{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Regression"
      ],
      "metadata": {
        "id": "f4_INnKC0NMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- What is Simple Linear Regression?\n"
      ],
      "metadata": {
        "id": "-EcS05h2nf5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Simple Linear Regression is a statistical method that models the linear relationship between a dependent variable \\( Y \\) and an independent variable \\( X \\).\n",
        "It is expressed as \\( Y = mX + c \\), where \\( m \\) is the slope and \\( c \\) is the intercept.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "WeZCtIhZsYuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- What are the key assumptions of Simple Linear Regression.\n"
      ],
      "metadata": {
        "id": "Cx0OIfXUnjgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''1. **Linearity**: The relationship between \\( X \\) and \\( Y \\) is linear.\n",
        "2. **Independence**: Observations are independent of each other.\n",
        "3. **Homoscedasticity**: Residuals have constant variance.\n",
        "4. **Normality of Residuals**: Residuals are normally distributed.\n",
        "5. **No Multicollinearity**: Only one predictor is present, so this is not applicable.\n",
        "'''"
      ],
      "metadata": {
        "id": "tY5aEUe7uJp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3- What does the coefficient m represent in the equation Y=mX+c.\n"
      ],
      "metadata": {
        "id": "o5m5dvEopewE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The coefficient \\( m \\) represents the slope, indicating the change in \\( Y \\) for a one-unit change in \\( X \\). '''"
      ],
      "metadata": {
        "id": "WMXWW_HBuOlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4- What does the intercept c represent in the equation Y=mX+c.\n"
      ],
      "metadata": {
        "id": "ujSDJpQXpesf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The intercept \\( c \\) represents the value of \\( Y \\) when \\( X = 0 \\). It is the starting point of the line on the \\( Y \\)-axis.'''"
      ],
      "metadata": {
        "id": "PsjtdylcuUkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5- How do we calculate the slope m in Simple Linear Regression.\n"
      ],
      "metadata": {
        "id": "5X999pEjpep1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The slope\n",
        "ùëö\n",
        "m is calculated as:m=Cov(X,Y)/Var(X)\n",
        "‚Äãwhere\n",
        "Cov(X,Y) is the covariance between\n",
        "X and Y, and\n",
        "Var(X) is the variance of\n",
        "X."
      ],
      "metadata": {
        "id": "HMXBpY9TuZ1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6- What is the purpose of the least squares method in Simple Linear Regression.\n"
      ],
      "metadata": {
        "id": "_jXYt62Upem9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The least squares method minimizes the sum of squared residuals (differences between observed and predicted values) to find the best-fitting line.'''"
      ],
      "metadata": {
        "id": "jmcHdbekxflR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7- How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression.\n"
      ],
      "metadata": {
        "id": "uq-oUuAYpekW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\\( R^2 \\) represents the proportion of variance in \\( Y \\) explained by \\( X \\). Values closer to 1 indicate a better fit.'''"
      ],
      "metadata": {
        "id": "X0RVCLJFxjs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8- What is Multiple Linear Regression.\n"
      ],
      "metadata": {
        "id": "q3Dal7B4pehg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Multiple Linear Regression is a statistical method that models the relationship between a dependent variable and two or more independent variables, expressed as:\n",
        "\n",
        "ùëå= ùëè0 + ùëè1ùëã1 + ùëè2ùëã2 + ‚Ä¶ + ùëèùëõùëãùëõ\n"
      ],
      "metadata": {
        "id": "ns9xqqV5xpLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9- What is the main difference between Simple and Multiple Linear Regression.\n"
      ],
      "metadata": {
        "id": "C90fDU9Wpeew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses two or more independent variables.'''"
      ],
      "metadata": {
        "id": "m7OzUUEeyDs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10- What are the key assumptions of Multiple Linear Regression.\n"
      ],
      "metadata": {
        "id": "Yf92YlXLpecL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Linearity: The relationship between predictors and Y is linear.\n",
        "Independence: Observations are independent.\n",
        "Homoscedasticity: Residuals have constant variance.\n",
        "Normality of Residuals: Residuals follow a normal distribution.\n",
        "No Multicollinearity: Independent variables are not highly correlated.\n",
        "'''"
      ],
      "metadata": {
        "id": "7_fnIyzhyHkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11- What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model.\n",
        "\n"
      ],
      "metadata": {
        "id": "gDW9Du2UpeZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Heteroscedasticity occurs when the variance of residuals is not constant across levels of the predictors.\n",
        "It can lead to inefficient estimates and unreliable hypothesis tests.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Ibt5q5WgyMbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12- How can you improve a Multiple Linear Regression model with high multicollinearity.\n"
      ],
      "metadata": {
        "id": "cO1wZ33BpeWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Remove or combine highly correlated variables.\n",
        "Use regularization methods like Ridge or Lasso regression.\n",
        "Standardize or normalize predictors to reduce variance inflation.\n",
        "'''"
      ],
      "metadata": {
        "id": "Dv1lZ5AFyQ7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13- What are some common techniques for transforming categorical variables for use in regression models.\n"
      ],
      "metadata": {
        "id": "kprSPuSTpeUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''One-hot encoding\n",
        "Label encoding\n",
        "Dummy variable creation\n",
        "Binary encoding'''"
      ],
      "metadata": {
        "id": "-OkNr9ltyUTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14- What is the role of interaction terms in Multiple Linear Regression.\n"
      ],
      "metadata": {
        "id": "pdwTCLcIpeRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Interaction terms capture the combined effect of two or more variables on Y,\n",
        "allowing the model to account for situations where the relationship between one predictor and\n",
        "Y depends on another predictor.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "NcM16wp6yXtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15- How can the interpretation of intercept differ between Simple and Multiple Linear Regression.\n"
      ],
      "metadata": {
        "id": "cnkq9asxpeOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''In Simple Linear Regression, the intercept represents Y when\n",
        "X=0. In Multiple Linear Regression, it represents\n",
        "Y when all predictors are zero, which may not always be meaningful.'''"
      ],
      "metadata": {
        "id": "rcG6e6jWyeTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16- What is the significance of the slope in regression analysis, and how does it affect predictions.\n"
      ],
      "metadata": {
        "id": "8aonunNCpeLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The slope represents the expected change in Y for a one-unit change in X. It determines the strength and direction of the relationship between variables.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "JQCLmTZeynHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17- How does the intercept in a regression model provide context for the relationship between variables.\n"
      ],
      "metadata": {
        "id": "s3VUp5bLpeIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The intercept provides a baseline value for Y when all predictors are zero, helping to contextualize and interpret the relationship.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "H1VqX8e-ytXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18- What are the limitations of using R¬≤ as a sole measure of model performance.\n"
      ],
      "metadata": {
        "id": "2rRntVh8peFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''It does not account for overfitting.\n",
        "It does not indicate the significance of predictors.\n",
        "It does not measure predictive accuracy on unseen data.\n",
        "'''"
      ],
      "metadata": {
        "id": "CvL_bfAiyzZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19- How would you interpret a large standard error for a regression coefficient.\n"
      ],
      "metadata": {
        "id": "WRJ0jxP7peCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''A large standard error indicates high variability in the coefficient estimate, making it less reliable and potentially non-significant.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "3KW-pjUdy3lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20- How can heteroscedasticity be identified in residual plots, and why is it important to address it.\n"
      ],
      "metadata": {
        "id": "TuM2oCvUpd_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Heteroscedasticity is identified by a funnel-shaped pattern in residual plots. Addressing it ensures unbiased and efficient estimates.'''"
      ],
      "metadata": {
        "id": "wBWYGKCYy8Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21- What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤.\n"
      ],
      "metadata": {
        "id": "QxBO2c5kpd8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''This indicates overfitting, where irrelevant predictors inflate R^2 but do not improve model performance.'''"
      ],
      "metadata": {
        "id": "VgMnx-o5y-8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22- Why is it important to scale variables in Multiple Linear Regression.\n"
      ],
      "metadata": {
        "id": "Jl7GWlQMpd5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Scaling ensures variables are on comparable scales, preventing one variable from dominating due to its magnitude and improving numerical stability.'''"
      ],
      "metadata": {
        "id": "ZgZ4YK5azIv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23- What is polynomial regression.\n"
      ],
      "metadata": {
        "id": "Z7atxTDYpd2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Polynomial regression models the relationship between X and Y as a polynomial function, allowing for nonlinear relationships'''"
      ],
      "metadata": {
        "id": "bc8PCXRwzLj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24- How does polynomial regression differ from linear regression.\n"
      ],
      "metadata": {
        "id": "ueekToZvpcgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Linear regression models straight-line relationships, while polynomial regression can model curved relationships by including higher-order terms.'''"
      ],
      "metadata": {
        "id": "GfcejiPezVCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25- When is polynomial regression used.\n"
      ],
      "metadata": {
        "id": "h-gGZpPAqpls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Polynomial regression is used when the relationship between variables is nonlinear but can be approximated with a polynomial function.'''"
      ],
      "metadata": {
        "id": "fT6e1ituzYa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "26- What is the general equation for polynomial regression.\n"
      ],
      "metadata": {
        "id": "yPczJJoLqqWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''ùëå= ùëè0 + ùëè1ùëã1 + ùëè2ùëã2 + ‚Ä¶ + ùëèùëõùëãùëõ'''"
      ],
      "metadata": {
        "id": "qhafTJH7zcQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27- Can polynomial regression be applied to multiple variables.\n"
      ],
      "metadata": {
        "id": "z8Idu9qHqqTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Yes, polynomial regression can be applied to multiple variables by including polynomial terms and their interactions.'''"
      ],
      "metadata": {
        "id": "XU75ohC2znkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "28- What are the limitations of polynomial regression.\n"
      ],
      "metadata": {
        "id": "L9l_AU-YqqQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''High-degree polynomials can overfit the data.\n",
        "Sensitive to outliers.\n",
        "Difficult to interpret coefficients for higher-order terms.'''"
      ],
      "metadata": {
        "id": "f6-1YvKQzqI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "29- What methods can be used to evaluate model fit when selecting the degree of a polynomial.\n"
      ],
      "metadata": {
        "id": "wJq5EU93qqNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Cross-validation\n",
        "Adjusted R^2\n",
        "Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC)\n",
        "Residual plots'''"
      ],
      "metadata": {
        "id": "zXYrgSAezsje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "30- Why is visualization important in polynomial regression.\n"
      ],
      "metadata": {
        "id": "mbNxQ8j6qqK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Visualization helps identify the degree of the polynomial that best fits the data and reveals patterns or residual issues.'''"
      ],
      "metadata": {
        "id": "io-snKfmzzqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "31- How is polynomial regression implemented in Python?"
      ],
      "metadata": {
        "id": "ibSQroZHqqH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sf695srndfo"
      },
      "outputs": [],
      "source": [
        "'''from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Fit the model\n",
        "model = LinearRegression().fit(X_poly, y)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QlhHfF1R0LuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yh8NJ7R1t0WE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##THEORETICAL"
      ],
      "metadata": {
        "id": "rEhzPnmYp_bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is Logistic Regression, and how does it differ from Linear Regression.\n"
      ],
      "metadata": {
        "id": "czwIddZZlGek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Logistic Regression is a statistical model used for binary classification.\n",
        "Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts probabilities for class membership.\n",
        "It applies the sigmoid function to transform linear predictions into probabilities.'''"
      ],
      "metadata": {
        "id": "57urhr9Aqog1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What is the mathematical equation of Logistic Regression.\n"
      ],
      "metadata": {
        "id": "YnA2E_aolGb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The Logistic Regression model is defined as:\n",
        "\n",
        "P(Y=1∣X)= 1 / 1+e^-(β0+β1X1+β2X2+...+βnXn)\n",
        "\n",
        "where\n",
        "\n",
        "P(Y=1∣X) is the probability of the positive class, and\n",
        "β are the model coefficients.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "BJgFRAWzqyJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Why do we use the Sigmoid function in Logistic Regression.\n"
      ],
      "metadata": {
        "id": "zmeFWiAZlGZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''The sigmoid function maps any real-valued number into the range (0,1),\n",
        "making it suitable for probability estimation.\n",
        "It ensures that the output is interpretable as a probability.\n",
        "\n",
        "σ(z)= 1 / 1+e^−z\n",
        "\n",
        "\n",
        "​\n",
        "'''"
      ],
      "metadata": {
        "id": "-KepU-qSrb8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What is the cost function of Logistic Regression.\n"
      ],
      "metadata": {
        "id": "D2G1U3nPlGWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Instead of Mean Squared Error (MSE),\n",
        "we use the log loss (cross-entropy loss):\n",
        "\n",
        "J(θ) = −1/m i=1∑m [yilog(y^i)+(1−yi)log(1−y^i)]\n",
        "This function penalizes incorrect predictions based on confidence.'''"
      ],
      "metadata": {
        "id": "njE58QkwrpfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What is Regularization in Logistic Regression? Why is it needed.\n"
      ],
      "metadata": {
        "id": "QZzDlKWOlGTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Regularization adds a penalty term to the cost function to prevent overfitting by discouraging large coefficients. Common types:\n",
        "\n",
        "L1 (Lasso): Adds absolute values of coefficients.\n",
        "L2 (Ridge): Adds squared values of coefficients.'''"
      ],
      "metadata": {
        "id": "ESWS1xMOsO9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Explain the difference between Lasso, Ridge, and Elastic Net regression.\n"
      ],
      "metadata": {
        "id": "uhj7UTY5lGQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Lasso (L1): Shrinks some coefficients to zero, performing feature selection.\n",
        "Ridge (L2): Shrinks coefficients but keeps all features.\n",
        "Elastic Net: Combines L1 and L2 regularization.'''"
      ],
      "metadata": {
        "id": "Xoomb1vjsSNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.When should we use Elastic Net instead of Lasso or Ridge.\n"
      ],
      "metadata": {
        "id": "kd4b_tvplGOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Elastic Net is preferable when:\n",
        "\n",
        "There are highly correlated features.\n",
        "We want sparse solutions but also retain some regularization.\n",
        "'''"
      ],
      "metadata": {
        "id": "5sRMHAX7sVF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is the impact of the regularization parameter (λ) in Logistic Regression.\n"
      ],
      "metadata": {
        "id": "1nWIV9UplGLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''High λ: More regularization → smaller coefficients → underfitting.\n",
        "Low λ: Less regularization → larger coefficients → risk of overfitting.\n",
        "'''"
      ],
      "metadata": {
        "id": "EZGGH2e0sYK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What are the key assumptions of Logistic Regression.\n"
      ],
      "metadata": {
        "id": "shdMADL3lGI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Linear relationship between predictors and log-odds.\n",
        "No multicollinearity (independent features).\n",
        "Independent observations.\n",
        "Large sample size for stability.\n",
        "'''"
      ],
      "metadata": {
        "id": "7i7L4NSysbFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.What are some alternatives to Logistic Regression for classification tasks.\n"
      ],
      "metadata": {
        "id": "MG33LH_rlGGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Decision Trees\n",
        "Random Forest\n",
        "Support Vector Machines (SVM)\n",
        "Neural Networks\n",
        "Naïve Bayes'''"
      ],
      "metadata": {
        "id": "JzIPFgLSseXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What are Classification Evaluation Metrics.\n"
      ],
      "metadata": {
        "id": "YdZn-WFFlGDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Accuracy\n",
        "Precision, Recall, F1-score\n",
        "ROC-AUC\n",
        "Log loss'''"
      ],
      "metadata": {
        "id": "n10EbBUhshVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.How does class imbalance affect Logistic Regression.\n"
      ],
      "metadata": {
        "id": "qXHvWo3PlGAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Model predicts the majority class more often.\n",
        "Poor recall for the minority class.\n",
        "Solutions: Resampling, class weights, SMOTE.'''"
      ],
      "metadata": {
        "id": "pheq61fQsj8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.What is Hyperparameter Tuning in Logistic Regression.\n"
      ],
      "metadata": {
        "id": "rag_WJZplF90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Finding optimal C (inverse of λ) for regularization.\n",
        "Choosing the best solver (liblinear, saga, etc.).\n",
        "Using Grid Search or Random Search for optimization.\n",
        "'''"
      ],
      "metadata": {
        "id": "pizUcZlzsqUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.What are different solvers in Logistic Regression? Which one should be used.\n"
      ],
      "metadata": {
        "id": "MfQmomfilF7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''liblinear: Good for small datasets (supports L1 & L2).\n",
        "saga: Best for large datasets with L1/L2.\n",
        "newton-cg: Good for L2 regularization.'''"
      ],
      "metadata": {
        "id": "siaqO7u1stby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.How is Logistic Regression extended for multiclass classification.\n"
      ],
      "metadata": {
        "id": "cCJk7cyblF4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''One-vs-Rest (OvR): Train a separate model for each class.\n",
        "Softmax Regression: Generalizes sigmoid for multiple classes.\n",
        "'''"
      ],
      "metadata": {
        "id": "UcyDvd6Tsv-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.What are the advantages and disadvantages of Logistic Regression.\n"
      ],
      "metadata": {
        "id": "GqGRf73AlF18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Advantages:\n",
        "\n",
        "Simple and interpretable.\n",
        "Works well with small datasets.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Assumes linear decision boundary.\n",
        "Can be sensitive to outliers.'''"
      ],
      "metadata": {
        "id": "bmkObZQWsy5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.What are some use cases of Logistic Regression.\n"
      ],
      "metadata": {
        "id": "3rOcI0f6lFzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Medical diagnosis (disease prediction).\n",
        "Spam detection.\n",
        "Credit risk assessment.'''"
      ],
      "metadata": {
        "id": "2JvUyF04s3cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.What is the difference between Softmax Regression and Logistic Regression.\n"
      ],
      "metadata": {
        "id": "uLinXNp2lFwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Logistic Regression: Used for binary classification.\n",
        "Softmax Regression: Used for multiclass classification.\n",
        "'''"
      ],
      "metadata": {
        "id": "izth3oDos53v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification.\n"
      ],
      "metadata": {
        "id": "xcjm-G6jlFtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''OvR: Better for imbalanced data.\n",
        "Softmax: More efficient for large datasets with balanced classes.\n",
        "'''"
      ],
      "metadata": {
        "id": "xUFiAudas8wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.How do we interpret coefficients in Logistic Regression?"
      ],
      "metadata": {
        "id": "tYFblYFAlFq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Exponentiate coefficients to get odds ratios.\n",
        "A positive coefficient increases the odds of class 1.\n",
        "A negative coefficient decreases the odds.'''"
      ],
      "metadata": {
        "id": "4uWjCwd1s_jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PRACTICAL"
      ],
      "metadata": {
        "id": "f4Pz5U9-p8Ke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n"
      ],
      "metadata": {
        "id": "FxI_CUSkmgc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN6c-Es7tXEK",
        "outputId": "199bf7b3-e963-4077-ff7d-defeb768df54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.\n"
      ],
      "metadata": {
        "id": "dgkvtlQEmgXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L1 Regularization: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVngbeYktkeg",
        "outputId": "59807d31-8e00-487f-deea-1fc06ecccb9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 0.9561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Write a Python program to train Logistic Regression with L2 regularization (Ridge) using Logistic Regression(penalty='l2'). Print model accuracy and coefficients.\n"
      ],
      "metadata": {
        "id": "gq_Y0lc_mgUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L2 Regularization: {accuracy:.4f}')\n",
        "\n",
        "# Print coefficients\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD8_hSCytrFP",
        "outputId": "93916f95-b2c6-4284-9c1c-8529be8832af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 0.9561\n",
            "Model Coefficients: [[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n"
      ],
      "metadata": {
        "id": "wFT4ZshMmgRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with Elastic Net\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with Elastic Net: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWMPc5G3tuz-",
        "outputId": "091663d7-38c2-4fc5-c8cb-cd044cdba122"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net: 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n"
      ],
      "metadata": {
        "id": "seatCiIumgOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# Load dataset\n",
        "data = load_digits()\n",
        "X, y = data.data, data.target  # Multiclass dataset\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression for multiclass classification using OVR\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Multiclass Classification Accuracy (OVR): {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42JLPBxutxS6",
        "outputId": "e6074baf-2e02-427f-998e-e6af1f941784"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Classification Accuracy (OVR): 0.9611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n"
      ],
      "metadata": {
        "id": "2eTcnOWJmgLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and hyperparameter grid\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and accuracy\n",
        "print(f'Best Parameters: {grid_search.best_params_}')\n",
        "print(f'Best Accuracy: {grid_search.best_score_:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feOKIUett24u",
        "outputId": "d0ac167a-7b09-40b5-eb52-a7e1597f300b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
            "Best Accuracy: 0.9626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n"
      ],
      "metadata": {
        "id": "vD0M3KOUmgIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Define model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Perform Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print average accuracy\n",
        "print(f'Average Accuracy: {scores.mean():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q2uxjUut-4g",
        "outputId": "e5ea2fb1-90b1-473a-a73c-2409efb149cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "mV5OQ42TmgFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from CSV\n",
        "# Replace 'data.csv' with the actual file path or make sure 'data.csv' is in the current working directory\n",
        "file_path = 'data.csv'  # Or provide the full path if the file is in a different directory\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found. Please check the file path and ensure the file exists.\")\n",
        "    # You can optionally add code here to handle the error, like asking the user to input the correct path.\n",
        "    # For example:\n",
        "    # file_path = input(\"Enter the correct file path: \")\n",
        "    # df = pd.read_csv(file_path)\n",
        "else:\n",
        "    X = df.drop(columns=['target'])  # Assuming 'target' is the label column\n",
        "    y = df['target']\n",
        "\n",
        "    # Split dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'Model Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd4bHT4muB0a",
        "outputId": "0524bf5a-f008-4a0a-fb70-ed6a2c499196"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file 'data.csv' was not found. Please check the file path and ensure the file exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n"
      ],
      "metadata": {
        "id": "8PmWDe1ymgC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and hyperparameter grid\n",
        "model = LogisticRegression(solver='saga', max_iter=1000)\n",
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 10),\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Perform RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and accuracy\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n",
        "print(f'Best Accuracy: {random_search.best_score_:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqZ-E25yuIUi",
        "outputId": "259be477-bb29-43b6-afa0-ef782569d60d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.004641588833612777}\n",
            "Best Accuracy: 0.9253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "30 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 76, in _check_solver\n",
            "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
            "ValueError: penalty=None is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.91428571        nan 0.91648352 0.92527473        nan\n",
            " 0.92527473        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n"
      ],
      "metadata": {
        "id": "w-6_NCMsmf_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_digits()\n",
        "X, y = data.data, data.target  # Multiclass dataset\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train One-vs-One (OvO) Logistic Regression\n",
        "model = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Multiclass Classification Accuracy (OvO): {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwFLHKVvuLgq",
        "outputId": "9d9a082c-b359-44b6-8547-2da4be18890e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Classification Accuracy (OvO): 0.9833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n"
      ],
      "metadata": {
        "id": "9WC2B5pSmf9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "K3rHWbziuRFl",
        "outputId": "672ecbf7-7d6f-4803-e081-cbc8a59b5f11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,Recall, and F1-Score.\n"
      ],
      "metadata": {
        "id": "RYCFGqjkmf6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Compute precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2j1sJbquYxR",
        "outputId": "38c628e5-1beb-4648-c1b8-bf3edc9ab39a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9459\n",
            "Recall: 0.9859\n",
            "F1-Score: 0.9655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "87CodJlymf4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train model with class weights\n",
        "model = LogisticRegression(class_weight=class_weight_dict, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with Class Weights: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l06Lr3PSubJd",
        "outputId": "da7176e3-b752-41e7-d352-bfcc4021358f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Class Weights: 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n"
      ],
      "metadata": {
        "id": "FLgZWCM5n8bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Select features and target\n",
        "df = df[['sex', 'age', 'fare', 'survived']].dropna()\n",
        "X = pd.get_dummies(df[['sex', 'age', 'fare']], drop_first=True)\n",
        "y = df['survived']\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "print(f'Titanic Dataset Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t47I6G_Pudwq",
        "outputId": "1cdaf5b8-66ad-423e-bb2f-ad1e9a0cc795"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic Dataset Accuracy: 0.7483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.\n"
      ],
      "metadata": {
        "id": "iy5BuxQEmf1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model on scaled data\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_scaled = accuracy_score(y_test, model.predict(X_test_scaled))\n",
        "print(f'Accuracy with Scaling: {accuracy_scaled:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBi4_kiLuhCi",
        "outputId": "5544e773-545f-45fd-8d65-fdad21c7dede"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Scaling: 0.7483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n"
      ],
      "metadata": {
        "id": "pCsKpLnHmfyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Compute ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:,1])\n",
        "print(f'ROC-AUC Score: {roc_auc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_cpmNKSujMw",
        "outputId": "8858a7a9-6bd8-4769-f3b1-ee9ce8847136"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.7473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n"
      ],
      "metadata": {
        "id": "0ZGWLzQTmfvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model with custom regularization strength\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_custom = accuracy_score(y_test, model.predict(X_test))\n",
        "print(f'Accuracy with C=0.5: {accuracy_custom:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rM6YME8ulK5",
        "outputId": "16dc8b09-9653-4557-c359-f5f33c770bb3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.7483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n"
      ],
      "metadata": {
        "id": "r4BoQwp4mftT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = pd.DataFrame({'Feature': df.columns[:-1], 'Coefficient': model.coef_[0]})\n",
        "feature_importance = feature_importance.sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "# Print important features\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkke1rTSuos5",
        "outputId": "a062242b-412d-4bdb-d05d-f3e7c623778b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature  Coefficient\n",
            "2    fare    -2.271211\n",
            "0     sex    -0.018521\n",
            "1     age     0.012864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score.\n"
      ],
      "metadata": {
        "id": "gh0TwU2WpVvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the correct X_test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute Cohen’s Kappa score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f'Cohen’s Kappa Score: {kappa_score:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HXTX6bYuugN",
        "outputId": "9db04bc4-291a-4ced-dfdf-5a4c6b2a2b44"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen’s Kappa Score: 0.4717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n"
      ],
      "metadata": {
        "id": "yUMO0i7GpXAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Compute precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "\n",
        "# Plot precision-recall curve\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8r0p9YbRuw6j",
        "outputId": "5641c1fd-0028-4495-a59c-4f64644a3f1a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n"
      ],
      "metadata": {
        "id": "riaU_qctpW5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(f'Accuracy with {solver}: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vEwBR1Gu3Jx",
        "outputId": "0c99c2a8-d40c-40a3-aae1-bc5e4172ee21"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear: 0.7483\n",
            "Accuracy with saga: 0.6294\n",
            "Accuracy with lbfgs: 0.7483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n"
      ],
      "metadata": {
        "id": "RYDg6QTnpW1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Train the model using the appropriate dataset\n",
        "model = LogisticRegression(max_iter=1000)  # Initialize the model\n",
        "model.fit(X_train, y_train)  # Fit the model to your training data\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)  # Use the same X_test used for y_test\n",
        "\n",
        "# Compute Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f'Matthews Correlation Coefficient: {mcc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfH6DQS-u5l4",
        "outputId": "73421420-2e63-481f-d9c1-6d382fb0bffd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient: 0.4717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "Tsy7eqHxpWzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on raw data\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "accuracy_raw = accuracy_score(y_test, model_raw.predict(X_test))\n",
        "\n",
        "# Train on standardized data\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "accuracy_scaled = accuracy_score(y_test, model_scaled.predict(X_test_scaled))\n",
        "\n",
        "print(f'Accuracy without Scaling: {accuracy_raw:.4f}')\n",
        "print(f'Accuracy with Scaling: {accuracy_scaled:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt-L8x6tu7mO",
        "outputId": "21c86c22-5687-4a5a-992c-2cf9c0a5d9ff"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 0.7483\n",
            "Accuracy with Scaling: 0.7483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n"
      ],
      "metadata": {
        "id": "x7TQcwThpWwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "C_values = [0.001, 0.01, 0.1, 1, 10]\n",
        "best_C, best_score = 0, 0\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, max_iter=1000)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    avg_score = scores.mean()\n",
        "    print(f'C={C}: Mean Accuracy = {avg_score:.4f}')\n",
        "\n",
        "    if avg_score > best_score:\n",
        "        best_C, best_score = C, avg_score\n",
        "\n",
        "print(f'Best C: {best_C} with Accuracy: {best_score:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHgttqoLu-BU",
        "outputId": "39f686e0-5db8-4f6f-9fa8-070229686d5c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.001: Mean Accuracy = 0.6707\n",
            "C=0.01: Mean Accuracy = 0.7075\n",
            "C=0.1: Mean Accuracy = 0.7881\n",
            "C=1: Mean Accuracy = 0.7829\n",
            "C=10: Mean Accuracy = 0.7829\n",
            "Best C: 0.1 with Accuracy: 0.7881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions."
      ],
      "metadata": {
        "id": "x8DP76MlpV0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'logistic_regression_model.pkl')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_pred_loaded = loaded_model.predict(X_test)\n",
        "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
        "\n",
        "print(f'Accuracy of Loaded Model: {accuracy_loaded:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W8_SXC5vAcI",
        "outputId": "0c55eb5b-ab26-4a53-e93d-65b7ff6bac88"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Loaded Model: 0.7483\n"
          ]
        }
      ]
    }
  ]
}